{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 Discussion Grading - Peer Evaluation Grade Calculation\n",
    "Jing Jiang\n",
    "\n",
    "2021-10-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The objective of this file is calculate the average peer-evaluation score for each student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Excel files downloaded from Canvas were used. Some students submitted files in other formats, such as a screenshot, a PDF, a Macbook Numebers. These files were excluded. Some students submtited Excel files, but changed the format of the table. It's adjusted mannually. \n",
    "\n",
    "Submissions with wrong group numbers (such as Group number = 10). These are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jillb\\OneDrive - UBC\\CONS 302 TA 2021Fall\\grading\\Module 1 peer evaluation files\\20211014\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\jillb\\OneDrive - UBC\\CONS 302 TA 2021Fall\\grading\\Module 1 peer evaluation files\\20211014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "os.chdir(r'C:\\Users\\jillb\\OneDrive - UBC\\CONS 302 TA 2021Fall\\grading\\Module 1 peer evaluation files\\20211014')\n",
    "FileList = glob.glob('*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all Excel files, append all rows together (Columns should be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create for loop\n",
    "df = pd.DataFrame()\n",
    "for File in FileList:\n",
    "         df = df.append(pd.read_excel(File), ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jillb\\OneDrive - UBC\\CONS 302 TA 2021Fall\\grading\\Module 1 peer evaluation files\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\jillb\\OneDrive - UBC\\CONS 302 TA 2021Fall\\grading\\Module 1 peer evaluation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('calculated_weight.xlsx', sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None, storage_options=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "Many repetitive columns occurred because some students changed the column names.\n",
    "\n",
    "Some repetitive columns occured because some students did not delete the sample names \"ABCDEFG\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jillb\\OneDrive - UBC\\CONS 302 TA 2021Fall\\grading\\Module 1 peer evaluation files\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\jillb\\OneDrive - UBC\\CONS 302 TA 2021Fall\\grading\\Module 1 peer evaluation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_excel('ï¼ˆadjusted) calculated_weight.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.iloc[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some students made a typo in the column name. And it was sorted to the top.\n",
    "df_new.rename(columns={\"Goup Number\": \"Group Number\"} ,errors=\"raise\", inplace = True)\n",
    "\n",
    "# Make name values lower case\n",
    "df_new['Participant Name'] = df_new['Participant Name'].astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data type of \"Participant Name\" from object to string \n",
    "df_new['Participant Name'] = df_new['Participant Name'].astype('|S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_new.groupby('Participant Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-064ea794ca74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_grouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_grouped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Peer-Review Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(self, numeric_only)\u001b[0m\n\u001b[0;32m   1494\u001b[0m         \u001b[0mName\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m         \"\"\"\n\u001b[1;32m-> 1496\u001b[1;33m         return self._cython_agg_general(\n\u001b[0m\u001b[0;32m   1497\u001b[0m             \u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m             \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m     ) -> DataFrame:\n\u001b[1;32m-> 1015\u001b[1;33m         agg_mgr = self._cython_agg_blocks(\n\u001b[0m\u001b[0;32m   1016\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_cython_agg_blocks\u001b[1;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No numeric types to aggregate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_mgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "mean_df = df_grouped.mean(df_grouped['Peer-Review Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_grouped = df_new.groupby('Participant Name')['Peer-Review Score'].mean().sort_values('Peer-Review Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Peer-Review Score'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     184\n",
       "unique      6\n",
       "top         5\n",
       "freq      153\n",
       "Name: Peer-Review Score, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['Peer-Review Score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new['Peer-Review Score'] = df_new['Peer-Review Score'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_grouped = df_new.groupby(['Participant Name'])['Peer-Review Score'].mean().sort_values('Peer-Review Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the same table again but include only orders where the total number of items (eg: total quantity for the order) was 10 items or fewer.\n",
    "\n",
    "temp3 = df3.groupby(['Country', pd.Grouper(key='Invoice')])['invoice_item_value','Quantity'].sum() #the value of all items and the quantity of all items in an invoice\n",
    "temp3 = pd.DataFrame(temp3)\n",
    "temp3 = temp3[temp3['Quantity'] < 11] #\"Quantity\" here represents the total number of items in an invoice\n",
    "temp4 = temp3.groupby(['Country'])['invoice_item_value','Quantity'].mean().sort_values('invoice_item_value') #\"Quantity\" here represents the average quantity per invoice in the subset\n",
    "temp4 = pd.DataFrame(temp4)\n",
    "temp4.rename(columns={'invoice_item_value':'Average Invoice Value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new.groupby('Participant Name',as_index = False)['Peer-Review Score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new['Peer-Review Score'].groupby(['Participant Name']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new['Participant Name'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning in python is a mess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too tired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gave up and used Excel pivot table to do matrices calculation instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
